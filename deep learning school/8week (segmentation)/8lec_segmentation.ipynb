{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сегментация\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Отличие сегментации от детекции в том, что мы для каждого пикселя определяем принадлежит ли он нашемму объекту или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic segmentation** - определить все объекты,  которые принадлежат одному классу, например просто выделить всех людей и закрасить их одним цветом \n",
    "\n",
    "**Instance segmentation** - определить все объекты, которые принадлежат одному классу, а затем еще среди них определить разные \"экземплляры\". То есть найти всех людей на картинке и разных людей в разный цвет раскрасить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сегментировать вообще все, а можно только некоторые объекты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача сегментации:** по входной картинке, для каждого пикселя картинки определить к какому классу он принадлежит, то есть мы должны заранее знать на какие классы мы хотим сегментировать картинку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сетка будет выдавать для каждого пикселя вероятность принадлежности к каждому классу, то есть выданная картинка будет как бы: HxWxClasses, то есть для каждого пикселя будет вектор вероятностей/логитов для классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Возвращать надо картинку такого же размера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и просто к каждому пикселю будем применять какой-то классификационный лосс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идеи решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Точно так же как мы при помощи лосса застявляем сетку обучаться на классификацию, мы можем заставить ее обучаться на сегментацию объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вокруг каждого пикселя берем окно вокруг него и затем для такого окна решаем простую задачу классификации изображения. Пикселю тогда просто присваиваем вектор вероятностей принадлежности, который получился для такого окна. Так мы все пиксели классифицируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Недостатки:**\n",
    "- вычислительно очень дорого\n",
    "- отдельные окна не шейрят информацию между собой о частях картинки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully-conv network (без FC слоев)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1XZl0m0UssG4lMUv2M4R_SP6LTJu4bZ98\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая фича мапа перед выходом - это слой из вероятности принадлежности каждого пикселя к классу, которому эта фича мапа соответствует. Мы учим сетку используя лосс, чтобы полученные фича мапы были картами сегментации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Короче сетка при помощи лосс функции сможет научиться сегментировать, она поймет, что лосс растет, если мы на выходе для 1 фича мапы выделяем только 1 класс, для 2 фича мапы выделяем только 2 класс и тд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- вычислительно еще дороже даже чем предыдущий способ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надо как-то сжимать информацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN + upsampling - тоже подход FCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учим сетку так, чтобы выходные фича мапы были картами сегментации для какого-то класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "испольховать просто архитектуру сверточной сети, там параметров надо гораздо меньше - размер сильно уменьшается от слоя к слою, а затем мы просто выходные фича увеличим в размерах - сделаем upsampling и потом объединим их в одну сегментированную картинку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблемы:** (из-за разрушения пространственной информации)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- upsampling плохо восстанавливает информацию\n",
    "\n",
    "- В данном подходе мы из-за upsampling, пулингов, большого страйда при свертке теряем пространственную информацию, это было полезно для простой задачи классификации, потому что нам надо было детектить собаку вне зависимости от того в какой части картинки она находится, но для сегментации это плохо, потому что нам надо сегментировать именно исходную картинку\n",
    "\n",
    "- Scale variability - котов разных размеров мы не сможем успешно сегментировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегментация сверточной сетью очень шумная и результат довольно плохой - процентов 70 пикселей правильно сегментированы, а спорные зоны вообще все неправильно сегментируются. Но! Люди придумали postprocessing (CRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение проблемы плохого восстановления информации при upsampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DeConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=15fFR8taeQNH3psMs0MA3LbyqA7InyMLd\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "никакой обратной свертки там не происходит, там происходит **Transposed convolution = upsampling + convolution**:\n",
    "\n",
    "- Маленькую фича мапу растягиваем upsampling-ом со страйдом - потом применяем ядро свертки к тому что заапсемплили, таким образом мы увеличиваем размер, но также еще какие-то параметры для ядер \"deconvolution\" обучаем при увеличивании размеров, однако по количеству параметров это на несколько порядков быстрее учится, чем если просто все гнать с огромным разрешением на всех свертках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://youtu.be/K73tZxH9nvE?t=533 - анимация того как происходит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "идея в том, чтобы не просто upsampling сделать, потеряв всю информацию, а попытаться как-то при увеличении разрешения картинки получить еще информацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Варианты upsampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Nearest neihbours\n",
    "\n",
    "2) Bed of Nails - втыкаем шапки гвоздей из нулей в фича мапу\n",
    "\n",
    "3) Bilinear\n",
    "\n",
    "4) Max-unpooling - происходит симметрично пуллингу, который происходил на прямом пути"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сетке не обязательно быть симметричной, также можно применть batch-norm и функции активации так же как при обычной свертке.\n",
    "\n",
    "Для меня удобно мыслить это как две отдельные части сетки:\n",
    "- сверточная часть сети\n",
    "- \"часть сети, которая увеличивает размер изображения\" - upsampling + convolution = deconvolution (опять же, без такого мы либо просто теряем кучу информации, если разрешение фича мапов сильно уменьшается, либо вычисления будут просто неподъемными если все сверточные слои будут над картинками полного разрешения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение проблемы разрушения пространственной информации:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dialated convolutions - мы upsampl'им как бы фильтр:\n",
    "\n",
    "$$\n",
    "y[i] = \\sum_{k=1}^K x[i + r \\cdot k]w[k]\n",
    "$$\n",
    "\n",
    "r = 1 соответствует обычной свертке, если больше, то это как бы свертка с дырками - через (r-1) суммируем при свертке\n",
    "\n",
    "K - это размер фильтра\n",
    "\n",
    "$y[i]$ - элемент карты активации после свертки.\n",
    "\n",
    "\n",
    "$x[i]$ - элемент \n",
    "\n",
    "$w[i]$ - вес в фильтре на этой позиции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моя немного улучшенная запись запись для свертки:\n",
    "\n",
    "\n",
    "$$\n",
    "y[i][j] = \\sum_{m=1}^N\\sum_{k=1}^N x[i + r \\cdot k][j + r \\cdot m]w[k][m]\n",
    "$$\n",
    "\n",
    "$y[i][j]$ - элемент карты активации после свертки.\n",
    "\n",
    "$x[\\alpha][\\beta]$ - элемент исходной фича мапы, которую сворачиваем\n",
    "\n",
    "$w[\\gamma][\\delta]$ - вес в фильтре на этой позиции\n",
    "\n",
    "сворачиваем ядром NxN, r=1 - это обычная свертка, если r повышаем, это Dialated convolution\n",
    "\n",
    "При проходе ядром: индекс k - быстрый индекс - номер столбца, m - медленный индекс, номер строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В торче у обычной свертки есть параметр 'dialation=1' - он по умолчанию стоит 1 - то есть это простая свертка происходит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи такой свертки - чем больше r, тем больше будет область картинки, которую ядро накрывает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что в итоге имеем:**\n",
    "\n",
    "- Идея которую реализует такой подход заключается в том, чтобы иметь такое же количество параметров у ядра, однако каждая свертка будет содержать больше информации о пространственном положении, потому что мы как бы большую область накрываем, но с дырками. А так же наша выходная фича мапа будет маленького размера, мы как будто уже учли при такой свертке пуллинг и страйд при обычной свертке\n",
    "\n",
    "- Также это заменяет нам использование stride при свертке, а также pooling слоя, потому что все это уже реализует такой метод свертки, то есть нам не приходится использовать большой страйд и макс пуллинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Использовать это естественно надо только, когда нам надо сохранять пространственную информацию об объектах, поэтому при простой классификации изображений такое использовать наоборот не нужно, там нам наоборот желательно как можно меньше простравнственных связей сохранять, чтобы не переобучаться и уметь в любой части экрана кота распознать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решение проблемы Scale variabilty:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialated convolutions разных размеров могут выделять информацию об объектах разных размеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь можно использовать идею Inception - использовать параллельно ветки с разными dialation_rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1YZXkCqnNliAhwNTgfDPIPj8GREV6ZLnu\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно параллельно использовать разные пуллинги, потом апсемплить и конкатенировать:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1LhhWkj_qt7hm6Y2cPuneJncdUU4DgXxo\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует метод постпроцессинга Conditional Random Field - CRF, он позволяет еще более детальными сделать границы классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Архитектуры для сегментации:\n",
    "\n",
    "https://youtu.be/K73tZxH9nvE?t=1860"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектура UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1ZcrqFadpa7RGdR8MxY7sTNXyHnLgrGXv\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь реализован skip-connection тем же методом, как у DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сетка симметричная, конкатенация происходит вместе с симметричными up-conv слоями, слоев на выходе после conv - так у нас сразу фича мапы с одинаковым разрешением конкатенируются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Левая часть - Encoder - extracts what information\n",
    "\n",
    "Правая часть - Decoder - recovers where information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что дают такие skip connection'ы:**\n",
    "\n",
    "- Они позволяют нам получать некоторый доступ к пространственной информации при декодировании"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема сегментации пикселей на краях изображений**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появляется проблема того, что очень мало информации о краях изображения из-зак того как работает свертка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap-tile strategy: https://youtu.be/yEuIV5FsRMs?t=635\n",
    "\n",
    "- Чтобы ее решить мы просто зеркалим несколько пикселей по краям - как бы зеркальный паддинг, и тогда у нас все прекрасно сработает - в центре будет как раз вся картинка до паддинга и вся информация о краях при свертках будет получена\n",
    "  \n",
    "- И если зеркалить, то ничего страшного как бы при проходе ядром по этим отзеркаленным местам не произойдет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Необходимо выбрать другой лосс**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении у нас очень много места занимает фон или внутренности объектов, но нам-то важнее всего классификация тоненькой границы между объектами - это самое важное, поэтому надо как-то лосс корректировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Решение - взвешенный лосс - будем скейлить лосс в зависимости от нахождения на границе:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1apMoQABh4IPl2kCfcBy1GebwhyTU4ohs\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Пара слов о Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала решаем задачу детекции - она очевидно, вычислительно гораздо проще задачи сегментации. А затем мы внутри bounding boxes выполняем задачу сегментации"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8b603c973ef7f83aae64b632e2e67529bc0c014d258c607b969039a8c89a028"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
