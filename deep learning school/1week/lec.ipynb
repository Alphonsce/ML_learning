{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curse of Dimensionality:\n",
    "\n",
    "при большой размерности признаков в маленькой окрестности\n",
    "некоторого ответа уже ничего и не лежит и так наше предсказание будет неточным на больших размерностях обучающей выборки. (Объем n-размерного куба - объем n-размерного шара все больше и больше)\n",
    "\n",
    "Это влияет на точность kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scale:\n",
    "\n",
    "Если брать евклидову метрику, то один признак просто может перевесить все на себя из-за того, что у него просто цифры больше\n",
    "\n",
    "Что делать: 1)стандартизировать: \n",
    "$$\n",
    "x_i = \\dfrac{x_i-\\langle x_i \\rangle}{\\sigma_{x_i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача обучения:\n",
    "\n",
    "Задача обучения найти функцию, которая хорошо приближает реальную зависимость y(x),\n",
    "\n",
    "$\\hat{y}: X -> Y$\n",
    "\n",
    "Причем искать функцию мы будем из определенного параметризованного семейства функций (см презу)\n",
    "\n",
    "Обучение - это как раз подбор параметра для нашей функции из определенного параметризованного семейства функций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучении с учителем мы вводим loss function:\n",
    "$$\n",
    "L(y, \\hat{y}(x))\n",
    "$$\n",
    "\n",
    "И решаем задачу, находя как раз параметр $\\theta_{best}$ для нашей функции (среднее значение всех лосс функций называют просто loss)\n",
    "\n",
    "$$\n",
    "\\theta_{best}=\\underset{\\theta}{\\mathrm{argmin}}\n",
    "\\dfrac{1}{dataset\\_size}\\sum_i L(y^i, \\hat{y^i}(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример: в качестве семейства функций возьмем линейные функции, параметризованные  $\\theta_0,...,\\theta_n$, \n",
    "в качестве loss возьмем MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переобучение - слабая обобщающая способность, мы улавливаем несуществующие зависимости на обучающей выборке, которых для любых других данных у нас не будет.\n",
    "\n",
    "В этой ситуации качество на тестовых данных гораздо ниже, чем на обучающих\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение датасета на Train/Validation/Test\n",
    "\n",
    "Выбираем архитектуру, настраиваем гиперпараметры и обучаемся на train, проверяем качество на validation\n",
    "\n",
    "(на kaggle - тест отедльным файликом неразмеченные данные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики проверки качества мы не стремимся уменьшить, мы на них проверяем качество, поэтому они и являются показательными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "позволяет не тратить данные на validation. Например:\n",
    "делим датасет на 5 частей, делаем 5 актов обучения и тестирования:\n",
    "\n",
    "1) Обучаемся на 2-5 частях, тестируем на 1 части\n",
    "2) Обучаемся на 1, 3-5 частях, тестируем на 2 части,\n",
    ".\n",
    ".\n",
    "Получаем так 5 оценок качества и усредняем их."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a580c138f4db662cb789ef61185146b6c46ae1ff4ef67cbbee73541ad7e49f5c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
