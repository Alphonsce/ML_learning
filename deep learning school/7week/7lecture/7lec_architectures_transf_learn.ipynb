{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектуры CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без функций активации все нейронки были бы просто эквивалентны линейной модели (ну, с некоторыми оговорками по поводу других слоев)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Alex.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в первом слое свертка ядром 11на11 со страйдом 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Свертка ядром 1на1 зачем: (если из 384 получаем 256, то как 2д если мыслить: для каждого канала применяем свои 256 ядер: для 1 канала свои 256, для 2 свои 256 и тд, затем, все что для своего 1 ядра: суммируем - 1 карта активации из 256 получается, и так делаем со всеми 256 ядрами)\n",
    "\n",
    "1) важно, что применяется функция активации и мы добавляем нелинейность (сверточный слой - это простое линейное преобразвание, поэтому без функции активаии две свертки эквиваленты какой-то одной свертке)\n",
    "\n",
    "2) можем получить другое количество карт активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достижения AlexNet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- использование релу\n",
    "- параллельное обучение на нескольких карточках\n",
    "- Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сеть более глубокая, больше FC слоев, больше сверточных слоев (аж 19 в VGG19)\n",
    "- Ядра 3на3 были использованы, то есть более локальные/детальные паттерны могли быть замечены, потому что уже не область 11на11 делалась в 1 пиксель, а область всего 3на3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Затухание градиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема характерная для очень глубоких сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./gr_dec.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока градиент идет до самых первых весов, он затухает, а если сетка очень глубокая, то входные весы могут даже и не начать изменяться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- сигмоида - плохо, потому что производная сигмоиды почти не отличается от 0 вдали от x=0, что еще больше все усугубляет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip connection - решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./skip.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_3 = x_2 w_2 + x_1$ - x1 связываем с x3, перекидывая его без веса, тогда при дифференцировании $dx_3/dw_0$ будет уже в виде двух слагаемых, потому что теперь x3 зависит от двух предыдущих слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и таким образом мы на несколько порядков увеличиваем нужные нам градиенты в ранних слоях и все веса дальше будут хорошо обучаться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./skip2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы просто на выход получаем H = F(x) + X_input,  $dL/dw_0 = dL/dH (dH/dF *...+dH/dX_{input})=0.1(0.1*0.1 + 1)$ - во внутрь просто единичка добавляется и просто на 2 порядка увеличивается производная лосса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо к слою перед выходом прибавить просто самый стартовый вектор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "    '''Принцип скип коннекшн на примере двух сверточных слоев (одного сверточного блока):'''\n",
    "    identity = X        # сохраняем входной вектор, чтобы к самому выходу его прибавить\n",
    "    out = self.conv1(X)            # создаем out, чтобы случайно X глобальный не изменить и нормально сделать skip connection\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out)         # надо юзать два разных батч норм слоя, естественно, потому что там все характеристики разные\n",
    "\n",
    "    if self.downsample is not None:\n",
    "        identity = self.downsample(X)\n",
    "\n",
    "    out += identity         # На самом деле, после какого момента мы хотим сделать skip connection - \n",
    "                            # решать нам - это надо сделать, когда градиенты уже затухли в обратном направлении.\n",
    "    out = self.relu(out)\n",
    "\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естесна можно делать скип коннекшн несколько раз, сохраняя вектор, который прибавлять на разных этапах или все время один прибавляя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чаще всего он используется в CNN, \n",
    "\n",
    "- также он помогает в поздние слои сети протолкнуть информацию из ранних слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./res.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь представлены варианты одного FC блока для resnet - можно по разному ставить батч норм, прибавление коннекшн вектора и функцию активации для передачи в следующий блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно скип коннекшн юзают как раз по окончании блока (Dense block - как раз составные части):\n",
    "- сверточный блок - это то что сверху forward - два слоя свертки и потом прибавка вектора на входе в блок\n",
    "  \n",
    "- FC блок - сверху на картинке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сама ResNet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./res2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "стрелочки - как раз скип коннекшн перед выходом из блока - на входе в блок сохраняем входной вектор, потом им скипаем все преобразования, а с другим таким же вектором делаем все преборазования - перед выходом их складываем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас теперь еще появляется некоторый обходной путь, как данныые могут не напрямую попадать в следующие слои сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "каждый последующий слой сети получает на вход все выходы вообще всех предыдущих сетей: https://youtu.be/TcUPuKpIlhQ?t=2049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Таким образом каждый следующий слой получает все карты активации всех предыдущих слоев - он получает как низкоуровневую информацию, так и высокоуровневую"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./dense.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зеленый полчает все фича мапы с красного плюс еще создает свои 4 новые на основе полученных красных. Фиолетовый получает все с красного, зеленого и еще свои 4 создает на основе красных и зеленых, и так далее - каждый следующий слой строит новые gowth_rate карт\n",
    "\n",
    "потом просто в FC слои передаем финальный вектор, сконкатенировав выход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./dense2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "каждый блок состоять может из разного количества сверток - классический вариант две свертки 3на3 со всеми наворотами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1на1 свертку юзаем, чтобы новых ровно growth_rate карт активации получать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Очевидно, что на вот этих вот слоях свертки в dense net нам не надо юзать skip connection как-то отдельно, потому что здесь мы итак передаем вообще все с предыдущих слоев и градиент вообще не будет затухать - в этом главный плюс такой архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Более далекие слои таким образом могут паттерны и low level и high level замечать, что позволяет ей обучаться на не очень больштх данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использовать разные архитектуры блоков:\n",
    "- basic - две 3на3 свертки \n",
    "- bottleneck - 1на1 свертка, 3на3 свертка, 1на1 свертка\n",
    "- wide\n",
    "- pyramidal - размеры карт активации постепенно увеличиваются\n",
    "- pyramidal bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModileNet - оптимизирована для запуска с телефона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "на этом GoogleNet основана:\n",
    "\n",
    "мы параллельно слой прогоняем через свертки разных размеров и через разные пуллинги и потом конкатенируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://youtu.be/TcUPuKpIlhQ?t=2932 -объяснение GoogleNet\n",
    "\n",
    "Кратко: мы в разные части сети ставим FC слои и минимизируем сумму лоссов для всех таких выходов, за счет чего у нас не будут затухать градиенты, потому что 1 FC блок будет близко к началу, второй будет близко к середине, третий будет близко к концу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть skip connection не единственное возможное решение затухания градиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что делать если датасет содержит мало объектов, а обучать модель надо. Если объектов мало, то модель очень легко переобучить, она банально выучит всю выборку эту и будет давать на ней хорошую точность, а на любых других данных она еще ниче не умеет делать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine tuning (дообучение)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть обученная ResNet для классификации картинок на ImageNet на 1000 классов\n",
    "\n",
    "Мы хотим сетку, которая будет классифицировать диких животных, но изображений с ними у нас очень мало\n",
    "\n",
    "Обучать с нуля глупо - модель просто переобучится"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Просто инициализируем весы нашей сетки весами из обученной на ImageNet сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- было 1000 выходных нейронов, теперь их 10, возьмем и просто выкинем последний слой и весы в нем случайным образом инициализируем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но так все все равно переобучиться, мы просто инициализируем теперь не рандомами, а какими-то новыми весами другой сетки.\n",
    "\n",
    "- Нужно заморозить весы первых слоев, потому что там выделяются low level паттерны и по-сути там ничего особо обучаться и не будет, таким образом у нас будет обучаться гораздо меньше параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- можно только 2 последних не замораживать, а можно как-то по-другому, это все зависит от различия между датасетами, от объема датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Чем больше различие между датасетами и чем меньше размер датасета для target задачи, тем больще слев надо будет дообучать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./tl.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель выучивает распределение на лейблы при условии первой выборки, а мы хотим получить распределение на лейблы при услвоии второй выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TL делится на 2 или 3 части:\n",
    "\n",
    "на 2:\n",
    "1) Если разные домены (датасеты) - классифицировать цифры, но у source был датасет MNIST, а мы хотим на SVHN цифры классифицировать\n",
    "2) Разные задачи - оба датасета состоят из лиц людей, но в одном случае надо определять пол, а в другом расу по лицу\n",
    "\n",
    "на 3 вида: Это связано с тем, что: $P(Y|D)=\\dfrac{P(D|Y)P(Y)}{P(D)}$, здесь P - это именно распределение\n",
    "1) Ds $\\ne$ Dt\n",
    "   \n",
    "2) P(Ds) $\\ne$ P(Dt), то есть распределения признаков в доменах разные, то есть они например состоят оба из слов на русском языке, но в одном у нас больше слов про кино, в другом про игры.\n",
    "   \n",
    "3) P(Ys|Ds) $\\ne$ P(Yt|Dt) - то есть у нас совпадают датасеты - оба из лиц людей, но лейблы разные: в первом случае эмоцию определить, во втором пол"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Деление supervised/unsupervised: есть ли лейблы у Dt\n",
    "\n",
    "То есть мы хотим решать абсолютно такую же задачу, но в target domain у нас нет размеченных лейблов, у нас есть только признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как решать эти задачи transfer learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inter-domain информация - характерна обеим датасетам\n",
    "\n",
    "- intro-domain - информация характерная только target датасету"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Идея: fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Идея: если у нас нет лейблов на таргет домене, то можно как-то сделать так, что распределения выходов каждого слоя нашей известной сетки было таким же как распределение выходов для таргет сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Идея: Разбить сеть на много разных частей и пробовать выучивать то, что характерно для одного и другого датасетов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Идея - использовать выходы известной сети и с помощью лосса как-то сближать выходы нашей таргет сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Если мы просто будем генерировать данные, то у нас не будут совпадать распределения $P(D_s)$ - то что мы нагенерировали и $P(D_t)$ - какое есть распределение для реальных данных для объектов, которые мы генерировали. Если мы начнем просто обучать сетку на $P(D_t)$, то в реальном мире модель будет плохо работать, поэтому надо применять transfer learning для модели, которую мы обучили на сгенерированных данных, а потом уже на нашей какой-то маленькой выборке из реального мире обучать модель для реального мира"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a580c138f4db662cb789ef61185146b6c46ae1ff4ef67cbbee73541ad7e49f5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
