{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До нейронок для распознания изображений юзали Histogram of oriented gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение задачи без CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение задачи классификации на MNIST при помощи обычной полносвязной нейронной сети:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разворачиваем картинку в вектор 1x1024, то есть на вход будем принимать вектор из 1024 булевых значений, вот так прогоним через несколько слоев и в конце получим финальные логиты из которых получим вероятности принадлежности при помощи софтмакс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатки:\n",
    "- в первом слое слишком много нейронов, то есть слишком много обучаемых параметров, поэтому сильно переобучается\n",
    "- ломаются пространственные отношения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда человек смотрит на картинку, он распознает паттерны картинки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Свертка:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- У ЧБ картинки просто яркость от 0 до 255 делаем, про RGB ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Фильтр(ядро) - матрица NxN, которую мы применяем для свертки, мы поочередно накладываем фильтр на пиксели изображения и поэлементно перемножаем элементы фильтра на кусочек изображения NxN, а затем суммируем все эти произведения - по сути мы применяем то самое поэлементное тензорное умножение для ядра и всех подматриц NxN из матрицы изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Если была картинка 32на32, то станет 30на30 после свертки (уменьшение размера зависит от размера ядра свертки). Размер картинки изменяется на (N-1)x)(N-1) относительно его размера до свертки, при stride = 1. (если на ядре 3на3 рассматривать, то мы как бы не можем уже залезть на крайние 2 столбца/строки, поэтому размер уменьшается)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Картинка после свертки - карта активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используется для того, чтобы после свертки картинка не меняла свой размер - мы обрамляем исходную картинку квадратом из нулей и получим 34на34 и она перейдет в 32на32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Насколько мы смещаемся при поочередном накладывании фильтра на изображение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Свертка цветных картинок:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цветная картинка имеет суть как 3 ЧБ картинки - она представляется тензором размера Высота x Длина x 3 цветовых канала, внутри канала циферки тоже обозначают яркость данного цвета. Короче цветная картинка - это просто 3 двумерные картинки, а потом уже как хотим их сворачиваем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 3d свертка - тензор 3 ранга также поэлементно умножаем на фильтр - тензор 3 ранга и получаем двумерную карту активации\n",
    "2) 2d свертка по каждому каналу отдельно - получаем 3 карты активации для этого одного ядра - затем можно их выпрямить в векторы и получить уже вектор признаков для этого ядра либо подавать на следующий сверточный слой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Зачем нужны фильтры?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Фильтры реагируют на паттерны на изображении. Для примера : если выбрать фильтр, реагирующий на прямые линии, то при применении к изображению четверки, мы получим большие цифры на карте активации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Карты активации показывают, насколько сильно фильтр активировался на картинку, поэтому они и называются картами активации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Если мы применяем фильтр, который реагирует на какие-то паттерны и мы видим, что на карте активации большие числа, значит активация на фильтр сильная и там присутствуют паттерны, под которые подобран фильтр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Карта активации - это не то, что сохраняет какие-то части исходного изображения, все что она делает - показывает реакцию на фильтр, если на ней большие по модулю числа, то активация сильная, если маленькие - слабая (фильтр не сохраняет части исходного изображения, он работает как лампочка - загорается, когда паттерны подходящие под фильтр есть на изображении)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим мы получили две карты активации. Затем мы каждую из них flatten-им, потом эти векторы конкатенируем в один вектор и получаем входной слой. То есть при помощи карт активации мы получаем признаковое представление картинки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть как в итоге выглядит одна свертка:\n",
    "- Мы выбираем количество ядер свертки, их размеры и структуру\n",
    "- проходимся этими ядрами с установленным stride-ом по изображению - получаем карту активации для каждого ядра\n",
    "- flatten-им все карты активации\n",
    "- конкатенируем это все в один вектор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В итоге как cnn выглядит:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Подаем картинку\n",
    "2) Применяем несколько сверток\n",
    "3) Флаттеним полученные карты активации после сверточных слоев - получаем вектор, который олицетворяет нашу картинку\n",
    "4) Используем полученный вектор на входе в полносвязную сеть\n",
    "5) Полносвязная сеть выдает нам логиты\n",
    "6) Оцениваем модель на полученных логитах\n",
    "\n",
    "- Выпрямление после свертки означает, что мы закончили свертку и будем дальше передавать в FC слои полученый вектор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так ну и что, большие или маленькие числа на картах активации, как это нам поможет классифицировать картинки??? А очень просто: то что мы получаем на выходе из сверточного слоя можно мыслить как признаковое описание конкретной картинки, поэтому большие/мальенкие значения на карте активации соответствуют большому/маленькому значению признака в выходном векторе. Ну а тут уже все понятно, грубо говоря, у кого похожие признаки, те и похожи, а похожесть уже определяется минимумом лосс функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Несколько слоев сверток"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи нескольких слоев свертки можно уже работать с довольно сложными изображениями:\n",
    "- Каждый следующий слой свертки получает в качестве входов карты активации с предыдущего"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример: картинка 32на32 (рассмотрим один канал от этой картинки), все сворачиваем со stride=1\n",
    "\n",
    "- На 1 сверточном слое используем 5 ядер 3на3 --> получим 5 карт активации 30на30 (то есть имеем тензор 30на30на5)\n",
    "- Теперь на полученном тензоре используем 3 ядра свертки размера 3на3на5 --> получаем 3 карты активации размером 28на28 (то есть имеем тензор 28на28на3 после этого слоя)\n",
    "\n",
    "- Теперь можно было бы еще один сверточный слой сделать с ядрами размера NнаNна3 и получили бы тензор AxAxN и так можно до бесконечности сворачивать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Примеры результата прогона по 4 слоям свертки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша свертка состоит из 4 слоев и мы распознаем картинки с лицами людей, что в итоге будет получаться:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Если подавать на вход низкоуровневые паттерны(линии различные), то фильтры 1 слоя сверток будут содержать довольно большие числа - они активируются\n",
    "2) Если подавать изображения носа/рта/губ , то фильтры 2-го слоя будут наиболее четко активироваться\n",
    "3) И на последнем слое у нас будут карты активации содержать наибольшие числа, если мы подаем целую картинку лица, а если, например, подать туда картинку чайника, то там будут маленькие по модулю числа на картах активации\n",
    "4) Последний слой содержит самую высокоуровневую информацию, мы просто берем все карты активации с последнего слоя и растягиваем их и конкатенируем и получаем вектор признаков для данной картинки, который в FC сеть передаем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Получаем в конце FC конечные логиты и на них применяем softmax, затем считаем cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### О кросс-энтропии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На логитах FC слоя мы используем softmax (argmax - зло) и получаем вектор из вероятностей принадлежности к каждому классу, затем мы хотим ввести какую-то функцию потерь для того, чтобы понимать в какую сторону крутить веса, чтобы все было норм. А все норм тогда, когда у нас все вероятность для нужного класса близка к 1. Итак введем Cross-entropy loss-function для классификации на M классов:\n",
    "$$\n",
    "l = -\\sum_{c=1}^M y_{c}log(p_c)\n",
    "$$\n",
    "Здесь $y_c$ - 1 или 0 - принадлежность данного объекта размеченной выборки к классу под номером $c$, $p_c$ - наш $c$-ый выход софтмакса - предсказание вероятности для $c$ класса\n",
    "\n",
    "Cross-Entropy loss для данного батча - это сумма cross-entropy для каждого объекта из батча - обозначим это за L. Наша задача найти $\\nabla_{W_i} L$ - по всем i слоям FC сети - для этого мы просто юзаем бэкпроп - поочередно дифференцируем, ну и получаем че надо, затем по всех слоях обновляем все весы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функции активации на свертке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- После каждого слоя свертки надо применять функцию активации\n",
    "- Просто к каждому элементу каждой карты активации применяем функцию активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаемые параметры сверточных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**У FC слоев в CNN все ясно. А где обучаемые параметры у сверточных слоев??? Все ядра -- обучаемые параметры!!!!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В процессе обучения с учителем нейронная сеть должна сама подобрать ядра"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Все ядра обучаемые!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В процессе обучения фильтры следующих слоев подстративаются под предыдущие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Свертка - это просто линейная функция, поэтому конечно же по параметрам ядер можно искать производные функции потерь и подбирать их"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Элементы ядер точно так же бэкпропом подбираются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пуллинг - уменьшение размерностей карт активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачем нужен пуллинг:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- уменьшение размерности карт активации\n",
    "- уменьшение чувствительности к положению объектов на картинке (это полезно, так как если надо классифицировать цифру, то нам бы хотелось ее определить вне зависимости в центре она или сдвинута), понятно, что не на всех фотографиях кошки и собаки прямо в середине"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Чем больше stride - тем меньше будет карта активации, также padding позволяет наоборот делать картинку больше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Зачем уменьшать размерность:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Уменьшение размерности карт активации нужно для того, чтобы было меньше весов в FC части и все вычислялось быстрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Уменьшить число параметров в картах активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как оно работает:\n",
    "Делим карту активации на квадратики NxN и из каждого квадратика берем max или average значения и получаем уменьшенную новую карту активации (чем больше N, тем больше информации мы потеряем)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пулинг слой:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После получения карт актвиации из картинки (с предыдущего слоя) применяем пуллинг к каждой карте активации и получаем новые уменьшенные карты активации, которые потом передаем дальше/ выпрямляем и конкатенируем и передаем в FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Кратко про AlexNet:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input - CL1 - CL2 - CL3 -CL4 -CL5 - FCL6- FCL7 - FCL8\n",
    "\n",
    "CL - это conv + pool + ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При больших количествах карт активации лучше мыслить свертку как 3d процедуру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 227x227x3 (трехканальная картинка)\n",
    "  \n",
    "- CL1: 55x55x96 (получаем 96 карт активации размером 55x55) - можно либо 3d свертку юзать 96-ю разными трехмерными ядрами, либо можно поделить на 3 канала и каждый канал 32 ядрами свернуть и получить по 32 карты на каждый канал и соединить их снова в один тензор\n",
    "  \n",
    "- CL2: 27x27x256 - здесь мы получаем 256 карт активации, сворачивая 3d ядрами 256 раз(можно мыслить, что мы двигаем параллелипипед по большому параллелипипеду) или можно мыслить, что мы к каждой карте активации из входных 96 применяем некоторое количество ядер и в сумме применяем 256 ядер, то есть 256 карт активации\n",
    "  \n",
    "- CL3: 13x13x384 - свернули 384 разными 3d ядрами - получили 384 карты активации\n",
    "\n",
    "- CL4: 13x13x384 - свернули 384 разными 3d ядрами размера 1x1x384 или может можно мыслить так: применили по одной свертке ядрами 1x1 на каждой входной карте активации и получили другие 384 карты активации того же размера\n",
    "\n",
    "- CL5: 13x13x256 - применяем свертки 1х1x? на картах активации, где ? зависит от stride\n",
    "\n",
    "- Теперь этот выход пуллится, флэттенится и конкатенируются векторы - получаем вектор длины 4096 - его подаем в FC сетку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задачи CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Классификация\n",
    "2) Detection - по картинке нужно понять, есть ли на картинке определенные объекты, которые нам нужны и обвести их, если они есть (детекция объектов для беспилотных автомобилей, вообще у беспилотников надо вообще и сегментировать кучу всего и там вообще куча задач...)\n",
    "3) Segmentation - покрасить все пиксели, принадлежащие нужному нам объекту в определенный цвет (пример: сегментация опухали и здоровых тканей по снимку мозга)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще задачи:\n",
    "\n",
    "- поиск по изображениям\n",
    "- оценка положения/расстояния\n",
    "- OCR (optical character recogniton) - автоматический перевод/ улучшение качества фотографий/документов/скан чеков/визиток"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Video Understanding** - задача computer vision:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- image description (на стыке с NLP), например, описание того, что происходит на фотографии -- выделение в баундин боксы отдельных объектов и их описание\n",
    "- subtitles generation\n",
    "- action description -- описание того, что происходит на видео/картинке\n",
    "- **pose estimation** -- например, по видео, определять где находятся ключевые точки человека и в реальном времени по видео понимать как движутся эти ключевые точки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN (генеративные модели)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если совместить GAN и Pose estimation, то можно перенести движения одного человека на другого человека"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
