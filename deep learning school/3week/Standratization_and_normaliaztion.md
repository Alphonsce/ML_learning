## Стандартизация данных

После стандартизации: x - mu / sigma, то есть признак становится равным тому насколько он удален от среднего в единицах стандартного отклонения

Myth: standardizing variables makes them normal: https://junkcharts.typepad.com/numbersruleyourworld/2019/11/myth-standardizing-variables-makes-them-normal.html

https://www.quora.com/Is-it-valid-to-standardize-variables-with-non-normal-distribution :
главная причина зачем мы стандартизируем данные - это сделать этих все сравнимыми между собой, вне зависимости от их природы, поэтому и париться о том каким было изначальное распределение нам не надо

Стандартизация приводит признак к нормальному распределнию со средним 0 и сигмой 1, то есть мы приводим все данные к одному масштабу и к одному и тому же виду, но всему взаимоотношения сохраняются. (так будет, если данные были распределены по нормальному распределению, а если распределение было не нормальным, то мы просто немного изменим распределение так, чтобы все распределилось вокруг нуля) 

Деревья и их ансамбли не требуют никакой стандартизации, потому что они работают с логическими утверждениями относительно абсолютных значений величин, если $a >= b$, то и после стандартизации $a' >= b'$

Алгоритмы с l1, l2 регуляризацией и использующие функции расстояния очень чувствительны к нестандартизированным данным, потому что иначе мы можем не регуляризировать некоторые весы, потому что они дают меньший вклад в регуляризационное слагаемое только из-за того, что по своей природе признаки соответствующие этим весами имеют меньшие по порядку значения,

Стандартизация данных сохраняет всю необходимую статистическую информацию, но при этом все весы и все слагаемые в функциях расстояний будут теперь равноправными и благодаря этому модель сможет улавливать более сложные зависимости.

Стандартизация позволяет нам сравнивать один датасет с другим или один признак с другим, потому что теперь они имеют одинаковый вид

## Нормализация данных (min max normalization)

Тут мы тупо x - min / max - min

Нормализация не изменяет распределения данных, она лишь масштабирует все данные, располагая их от 0 до 1, то есть она оставляет абсолютно все то же самое, только теперь все имеют одинаковый масштаб